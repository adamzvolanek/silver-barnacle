
# Lecture 1.1 - History of Computing  
  
## Computer History  
  
Computers and all the respective technologies associated with them continue to expand and evolve at an alarming rate. Less than 20 years ago, the iPhone was released as one of the first smart phones to combine the mp3 player, phone, and web-browser. In your pocket, statistically an iPhone is a phone that is 15299% "better" when looking at the AnTuTu benchmarks, or 3459% "better" based on the Geekbench 4 benchmark. <sup>[1](https://gadgetversus.com/processor/apple-a4-vs-apple-a15-bionic/)</sup> These types of advances in technology are unprecedented, in another perspective, your parents as children and even as adults did not have cell-phones growing up.

Let's go back in time to see how it all started....

### Wayback Machine

While more rudimentary methods of counting existed prior, the first computational tool mentioned will include the Abacus from the ancient Roman times. These were used as counters at the time and iterations appeared through the world as time marched on. Hundreds' of years later the Sliderule was invented in 1621. Using logarithmic scales, the logarithms are inscribed onto strips of wood and used to make quick calculations. Selecting fast-forward through time, the Colossus I was built-in 1943 and proved to be one of the first successful electronic computer built-in England. Hinted by the date of the creation, the computers purpose was designed to break World War II codes and could not be re-programmed for a different purpose.

These computers taking up entire floors of buildings to do computations that we may find trivial, in 1944 the first computer bug was found. In the sense that a dead moth in the deceased mechanism with its wings blocking the reading of the holes in the paper tape.

Continued improvements to make computers smaller and smaller started with the creation of the transistor in 1948. While computers did not transition until the period of 1956-1959, this phase was considered a turning point in computational advancement. Leaps were made following the 1950's with early programming languages like FORTRAN, COBOL, and BASIC were developed and integrated circuits in the 70s. For example, in 1971 Intel created the first microprocessor chip that could contain a total of 4-bits at the size of 1/16 x 1/8 inches (smaller than a dime), and contained 250 transistors. The 4 bit processing power matched an IBM competitor the size of an office desk while being at such a small size.

### Moore's Law

The remainder of tech exploded from the creation of the transistor and microprocessors. Where Moore's Law <sup>[2](https://en.wikipedia.org/wiki/Moore%27s_law)</sup> was loosely followed until today. Advancements in smaller microprocessors packing a greater number of transistors able to compute more complex calculations began to enter the main stream consumer markets.

Additionally, it was at this point in time where advancements in storage were made, transitioning from paper punch cards to floppy discs, cassette tapes, to cd's and dvd's.

## Footnote

While there are certainly additional gaps to fill in history of computers and like technologies, this is not designed to be a history course but to be more practical. However learning and having the understanding of how far computers have come in such short relative time should be realized; from floors of buildings filled with electronics and machines reading in paper forms with hole punches, to have the same power and more in the palm of everyone's pockets. The perspective that in the last 50-60 years, such leaps in technological advancement have not been seen, publicized, or used throughout the world, quite like computers, transistors, and everything in-between.
